/*
 * Live AI Manager
 * åå°ç®¡ç† Live AI ä¼šè¯ - æ”¯æŒ Siri å’Œå¿«æ·æŒ‡ä»¤æ— éœ€è§£é”æ‰‹æœº
 */

import Foundation
import SwiftUI
import AVFoundation

// MARK: - Live AI Manager

@MainActor
class LiveAIManager: ObservableObject {
    static let shared = LiveAIManager()

    @Published var isRunning = false
    @Published var isConnected = false
    @Published var errorMessage: String?

    // ä¾èµ–
    private(set) var streamViewModel: StreamSessionViewModel?
    private var omniService: OmniRealtimeService?
    private var geminiService: GeminiLiveService?
    private var provider: LiveAIProvider = .alibaba

    // è§†é¢‘å¸§
    private var currentVideoFrame: UIImage?
    private var isImageSendingEnabled = false
    private var frameUpdateTimer: Timer?

    // å¯¹è¯å†å²
    private var conversationHistory: [ConversationMessage] = []

    // TTS
    private let tts = TTSService.shared

    private init() {
        // ç›‘å¬ Intent è§¦å‘
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleLiveAITrigger(_:)),
            name: .liveAITriggered,
            object: nil
        )
    }

    /// è®¾ç½® StreamSessionViewModel å¼•ç”¨
    func setStreamViewModel(_ viewModel: StreamSessionViewModel) {
        self.streamViewModel = viewModel
    }

    @objc private func handleLiveAITrigger(_ notification: Notification) {
        Task { @MainActor in
            await startLiveAISession()
        }
    }

    // MARK: - Start Session

    /// å¯åŠ¨ Live AI ä¼šè¯ï¼ˆåå°æ¨¡å¼ï¼‰
    func startLiveAISession() async {
        guard !isRunning else {
            print("âš ï¸ [LiveAIManager] Already running")
            return
        }

        guard let streamViewModel = streamViewModel else {
            print("âŒ [LiveAIManager] StreamViewModel not set")
            tts.speak("Live AI æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆæ‰“å¼€åº”ç”¨")
            return
        }

        // è·å– API Key
        let apiKey = APIProviderManager.staticLiveAIAPIKey
        guard !apiKey.isEmpty else {
            errorMessage = "è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® API Key"
            tts.speak("è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® API Key")
            return
        }

        isRunning = true
        errorMessage = nil
        conversationHistory = []

        // è·å–å½“å‰ provider
        provider = APIProviderManager.staticLiveAIProvider

        print("ğŸš€ [LiveAIManager] Starting Live AI session...")

        do {
            // 1. æ£€æŸ¥è®¾å¤‡æ˜¯å¦å·²è¿æ¥
            if !streamViewModel.hasActiveDevice {
                print("âŒ [LiveAIManager] No active device connected")
                throw LiveAIError.noDevice
            }

            // 2. å¯åŠ¨è§†é¢‘æµï¼ˆå¦‚æœæœªå¯åŠ¨ï¼‰
            if streamViewModel.streamingStatus != .streaming {
                print("ğŸ“¹ [LiveAIManager] Starting stream...")
                await streamViewModel.handleStartStreaming()

                // ç­‰å¾…æµè¿›å…¥ streaming çŠ¶æ€ï¼ˆæœ€å¤š 5 ç§’ï¼‰
                var streamWait = 0
                while streamViewModel.streamingStatus != .streaming && streamWait < 50 {
                    try await Task.sleep(nanoseconds: 100_000_000) // 0.1ç§’
                    streamWait += 1
                }

                if streamViewModel.streamingStatus != .streaming {
                    print("âŒ [LiveAIManager] Failed to start streaming")
                    throw LiveAIError.streamNotReady
                }
            }

            // 3. é¢„é…ç½®éŸ³é¢‘ä¼šè¯ï¼ˆåå°æ¨¡å¼éœ€è¦ï¼‰
            try configureAudioSessionForBackground()

            // 4. åˆå§‹åŒ– AI æœåŠ¡
            initializeService(apiKey: apiKey)

            // 4. è¿æ¥ AI æœåŠ¡
            print("ğŸ”Œ [LiveAIManager] Connecting to AI service...")
            connectService()

            // ç­‰å¾…è¿æ¥æˆåŠŸï¼ˆæœ€å¤š 10 ç§’ï¼‰
            var connectWait = 0
            while !isConnected && connectWait < 100 {
                try await Task.sleep(nanoseconds: 100_000_000) // 0.1ç§’
                connectWait += 1
            }

            if !isConnected {
                print("âŒ [LiveAIManager] Failed to connect to AI service")
                throw LiveAIError.connectionFailed
            }

            // 5. å¯åŠ¨è§†é¢‘å¸§æ›´æ–°å®šæ—¶å™¨
            startFrameUpdateTimer()
            print("âœ… [LiveAIManager] Frame update timer started")

            // 6. ç›´æ¥å¼€å§‹å½•éŸ³ï¼ˆä¸æ’­æ”¾ TTSï¼Œé¿å…éŸ³é¢‘ä¼šè¯å†²çªï¼‰
            print("ğŸ¤ [LiveAIManager] About to start recording...")
            startRecording()

            print("âœ… [LiveAIManager] Live AI session started, ready to talk")

        } catch let error as LiveAIError {
            errorMessage = error.localizedDescription
            print("âŒ [LiveAIManager] LiveAIError: \(error)")
            await stopSession()
        } catch {
            errorMessage = error.localizedDescription
            print("âŒ [LiveAIManager] Error: \(error)")
            await stopSession()
        }
    }

    // MARK: - Audio Session Configuration

    /// é¢„é…ç½®éŸ³é¢‘ä¼šè¯ï¼ˆåå°æ¨¡å¼éœ€è¦åœ¨åˆå§‹åŒ–éŸ³é¢‘å¼•æ“ä¹‹å‰é…ç½®ï¼‰
    private func configureAudioSessionForBackground() throws {
        let audioSession = AVAudioSession.sharedInstance()

        // å…ˆåœç”¨å†é‡æ–°æ¿€æ´»ï¼Œç¡®ä¿å¹²å‡€çš„çŠ¶æ€
        do {
            try audioSession.setActive(false, options: .notifyOthersOnDeactivation)
            print("âœ… [LiveAIManager] éŸ³é¢‘ä¼šè¯å·²åœç”¨")
        } catch {
            print("âš ï¸ [LiveAIManager] åœç”¨éŸ³é¢‘ä¼šè¯å¤±è´¥: \(error)")
        }

        // é…ç½®éŸ³é¢‘ä¼šè¯
        try audioSession.setCategory(.playAndRecord, mode: .voiceChat, options: [.allowBluetooth, .allowBluetoothA2DP, .mixWithOthers])
        try audioSession.setActive(true)
        print("âœ… [LiveAIManager] åå°éŸ³é¢‘ä¼šè¯å·²é…ç½®: category=\(audioSession.category.rawValue), mode=\(audioSession.mode.rawValue)")
    }

    // MARK: - Initialize Service

    private func initializeService(apiKey: String) {
        switch provider {
        case .alibaba:
            omniService = OmniRealtimeService(apiKey: apiKey)
            setupOmniCallbacks()
        case .google:
            geminiService = GeminiLiveService(apiKey: apiKey)
            setupGeminiCallbacks()
        }
    }

    private func setupOmniCallbacks() {
        guard let omniService = omniService else { return }

        omniService.onConnected = { [weak self] in
            Task { @MainActor in
                self?.isConnected = true
                print("âœ… [LiveAIManager] Omni connected")
            }
        }

        omniService.onFirstAudioSent = { [weak self] in
            Task { @MainActor in
                print("âœ… [LiveAIManager] æ”¶åˆ°ç¬¬ä¸€æ¬¡éŸ³é¢‘å‘é€å›è°ƒï¼Œå¯ç”¨å›¾ç‰‡å‘é€")
                DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {
                    self?.isImageSendingEnabled = true
                }
            }
        }

        omniService.onSpeechStarted = { [weak self] in
            Task { @MainActor in
                if let strongSelf = self,
                   strongSelf.isImageSendingEnabled,
                   let frame = strongSelf.currentVideoFrame {
                    print("ğŸ¤ğŸ“¸ [LiveAIManager] æ£€æµ‹åˆ°ç”¨æˆ·è¯­éŸ³ï¼Œå‘é€å½“å‰è§†é¢‘å¸§")
                    strongSelf.omniService?.sendImageAppend(frame)
                }
            }
        }

        omniService.onUserTranscript = { [weak self] userText in
            Task { @MainActor in
                guard let self = self else { return }
                print("ğŸ’¬ [LiveAIManager] ç”¨æˆ·: \(userText)")
                self.conversationHistory.append(
                    ConversationMessage(role: .user, content: userText)
                )
            }
        }

        omniService.onTranscriptDone = { [weak self] fullText in
            Task { @MainActor in
                guard let self = self, !fullText.isEmpty else { return }
                print("ğŸ’¬ [LiveAIManager] AI: \(fullText)")
                self.conversationHistory.append(
                    ConversationMessage(role: .assistant, content: fullText)
                )
            }
        }

        omniService.onError = { [weak self] error in
            Task { @MainActor in
                self?.errorMessage = error
                print("âŒ [LiveAIManager] Omni error: \(error)")
            }
        }
    }

    private func setupGeminiCallbacks() {
        guard let geminiService = geminiService else { return }

        geminiService.onConnected = { [weak self] in
            Task { @MainActor in
                self?.isConnected = true
                print("âœ… [LiveAIManager] Gemini connected")
            }
        }

        geminiService.onFirstAudioSent = { [weak self] in
            Task { @MainActor in
                print("âœ… [LiveAIManager] æ”¶åˆ°ç¬¬ä¸€æ¬¡éŸ³é¢‘å‘é€å›è°ƒï¼Œå¯ç”¨å›¾ç‰‡å‘é€")
                DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {
                    self?.isImageSendingEnabled = true
                }
            }
        }

        geminiService.onSpeechStarted = { [weak self] in
            Task { @MainActor in
                if let strongSelf = self,
                   strongSelf.isImageSendingEnabled,
                   let frame = strongSelf.currentVideoFrame {
                    print("ğŸ¤ğŸ“¸ [LiveAIManager] æ£€æµ‹åˆ°ç”¨æˆ·è¯­éŸ³ï¼Œå‘é€å½“å‰è§†é¢‘å¸§")
                    strongSelf.geminiService?.sendImageInput(frame)
                }
            }
        }

        geminiService.onUserTranscript = { [weak self] userText in
            Task { @MainActor in
                guard let self = self else { return }
                print("ğŸ’¬ [LiveAIManager] ç”¨æˆ·: \(userText)")
                self.conversationHistory.append(
                    ConversationMessage(role: .user, content: userText)
                )
            }
        }

        geminiService.onTranscriptDone = { [weak self] fullText in
            Task { @MainActor in
                guard let self = self, !fullText.isEmpty else { return }
                print("ğŸ’¬ [LiveAIManager] AI: \(fullText)")
                self.conversationHistory.append(
                    ConversationMessage(role: .assistant, content: fullText)
                )
            }
        }

        geminiService.onError = { [weak self] error in
            Task { @MainActor in
                self?.errorMessage = error
                print("âŒ [LiveAIManager] Gemini error: \(error)")
            }
        }
    }

    // MARK: - Connection

    private func connectService() {
        switch provider {
        case .alibaba:
            omniService?.connect()
        case .google:
            geminiService?.connect()
        }
    }

    private func startRecording() {
        print("ğŸ¤ [LiveAIManager] å¼€å§‹å½•éŸ³")
        switch provider {
        case .alibaba:
            omniService?.startRecording()
        case .google:
            geminiService?.startRecording()
        }
    }

    private func stopRecording() {
        print("ğŸ›‘ [LiveAIManager] åœæ­¢å½•éŸ³")
        switch provider {
        case .alibaba:
            omniService?.stopRecording()
        case .google:
            geminiService?.stopRecording()
        }
    }

    // MARK: - Frame Update

    private func startFrameUpdateTimer() {
        frameUpdateTimer?.invalidate()
        frameUpdateTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
            Task { @MainActor in
                self?.updateVideoFrame()
            }
        }
    }

    private func updateVideoFrame() {
        if let frame = streamViewModel?.currentVideoFrame {
            currentVideoFrame = frame
        }
    }

    // MARK: - Stop Session

    /// åœæ­¢ Live AI ä¼šè¯
    func stopSession() async {
        guard isRunning else { return }

        print("ğŸ›‘ [LiveAIManager] Stopping session...")

        // åœæ­¢å®šæ—¶å™¨
        frameUpdateTimer?.invalidate()
        frameUpdateTimer = nil

        // åœæ­¢å½•éŸ³
        stopRecording()

        // ä¿å­˜å¯¹è¯
        saveConversation()

        // æ–­å¼€è¿æ¥
        switch provider {
        case .alibaba:
            omniService?.disconnect()
        case .google:
            geminiService?.disconnect()
        }

        // åœæ­¢è§†é¢‘æµ
        await streamViewModel?.stopSession()

        // é‡ç½®çŠ¶æ€
        omniService = nil
        geminiService = nil
        isConnected = false
        isRunning = false
        isImageSendingEnabled = false
        currentVideoFrame = nil

        print("âœ… [LiveAIManager] Session stopped")
    }

    /// ä¿å­˜å¯¹è¯åˆ°å†å²è®°å½•
    private func saveConversation() {
        guard !conversationHistory.isEmpty else {
            print("ğŸ’¬ [LiveAIManager] æ— å¯¹è¯å†…å®¹ï¼Œè·³è¿‡ä¿å­˜")
            return
        }

        let aiModel: String
        switch provider {
        case .alibaba:
            aiModel = "qwen3-omni-flash-realtime"
        case .google:
            aiModel = "gemini-2.0-flash-exp"
        }

        let record = ConversationRecord(
            messages: conversationHistory,
            aiModel: aiModel,
            language: "zh-CN"
        )

        ConversationStorage.shared.saveConversation(record)
        print("ğŸ’¾ [LiveAIManager] å¯¹è¯å·²ä¿å­˜: \(conversationHistory.count) æ¡æ¶ˆæ¯")
    }

    /// æ‰‹åŠ¨è§¦å‘åœæ­¢ï¼ˆä» UI è°ƒç”¨ï¼‰
    func triggerStop() {
        Task { @MainActor in
            await stopSession()
        }
    }
}

// MARK: - Live AI Error

enum LiveAIError: LocalizedError {
    case noDevice
    case streamNotReady
    case connectionFailed
    case noAPIKey

    var errorDescription: String? {
        switch self {
        case .noDevice:
            return "çœ¼é•œæœªè¿æ¥ï¼Œè¯·å…ˆåœ¨ Meta View ä¸­é…å¯¹çœ¼é•œ"
        case .streamNotReady:
            return "è§†é¢‘æµå¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥çœ¼é•œè¿æ¥çŠ¶æ€"
        case .connectionFailed:
            return "AI æœåŠ¡è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ"
        case .noAPIKey:
            return "è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® API Key"
        }
    }
}
