/*
 * TTS Service
 * æ–‡æœ¬è½¬è¯­éŸ³æœåŠ¡ - ä½¿ç”¨é˜¿é‡Œäº‘ qwen3-tts-flash API
 * ä½¿ç”¨å’Œ OmniRealtimeService ç›¸åŒçš„ AVAudioEngine æ–¹å¼æ’­æ”¾
 */

import AVFoundation
import Foundation

@MainActor
class TTSService: NSObject, ObservableObject {
    static let shared = TTSService()

    @Published var isSpeaking = false

    private let baseURL = "https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation"
    private let model = "qwen3-tts-flash"

    // æ ¹æ®å½“å‰è¯­è¨€è®¾ç½®è·å–è¯­éŸ³
    private var voice: String {
        return LanguageManager.staticTtsVoice
    }

    // æ ¹æ®å½“å‰è¯­è¨€è®¾ç½®è·å–è¯­è¨€ç±»å‹
    private var languageType: String {
        return LanguageManager.staticApiLanguageCode
    }

    // ä½¿ç”¨å’Œ OmniRealtimeService ä¸€æ ·çš„ AVAudioEngine æ–¹å¼
    private var playbackEngine: AVAudioEngine?
    private var playerNode: AVAudioPlayerNode?
    // ä½¿ç”¨ Float32 æ ‡å‡†æ ¼å¼ï¼Œå…¼å®¹ iOS 18+
    private let playbackFormat = AVAudioFormat(standardFormatWithSampleRate: 24000, channels: 1)
    private var isPlaybackEngineRunning = false

    private var currentTask: Task<Void, Never>?
    private var systemSynthesizer: AVSpeechSynthesizer?

    private override init() {
        super.init()
        setupPlaybackEngine()
    }

    // MARK: - Audio Engine Setup (å’Œ OmniRealtimeService ä¸€æ ·)

    private func setupPlaybackEngine() {
        playbackEngine = AVAudioEngine()
        playerNode = AVAudioPlayerNode()

        guard let playbackEngine = playbackEngine,
              let playerNode = playerNode,
              let playbackFormat = playbackFormat else {
            print("âŒ [TTS] æ— æ³•åˆå§‹åŒ–æ’­æ”¾å¼•æ“")
            return
        }

        playbackEngine.attach(playerNode)
        playbackEngine.connect(playerNode, to: playbackEngine.mainMixerNode, format: playbackFormat)
        playbackEngine.prepare()

        print("âœ… [TTS] æ’­æ”¾å¼•æ“åˆå§‹åŒ–å®Œæˆ: Float32 @ 24kHz")
    }

    /// é…ç½®éŸ³é¢‘ä¼šè¯ï¼ˆéœ€è¦åœ¨å¯åŠ¨æ’­æ”¾å¼•æ“ä¹‹å‰è°ƒç”¨ï¼‰
    private func configureAudioSession() {
        do {
            let audioSession = AVAudioSession.sharedInstance()

            // æ£€æŸ¥å½“å‰ä¼šè¯çŠ¶æ€
            print("ğŸ”Š [TTS] å½“å‰éŸ³é¢‘ä¼šè¯: category=\(audioSession.category.rawValue), mode=\(audioSession.mode.rawValue)")

            // åªåœ¨éœ€è¦æ—¶é…ç½®ï¼Œé¿å…ä¸ç°æœ‰ä¼šè¯å†²çª
            // ä½¿ç”¨å’Œ OmniRealtimeService å®Œå…¨ä¸€æ ·çš„è®¾ç½®ï¼ˆä¸è¦ defaultToSpeakerï¼‰
            try audioSession.setCategory(.playAndRecord, mode: .voiceChat, options: [.allowBluetooth, .allowBluetoothA2DP])
            try audioSession.setPreferredSampleRate(24000)
            try audioSession.setActive(true, options: [.notifyOthersOnDeactivation])
            print("âœ… [TTS] Audio session å·²é…ç½®")
        } catch {
            print("âš ï¸ [TTS] Audio session é…ç½®å¤±è´¥: \(error), ç»§ç»­å°è¯•æ’­æ”¾...")
            // ä¸è¦æŠ›å‡ºé”™è¯¯ï¼Œå°è¯•ä½¿ç”¨ç°æœ‰ä¼šè¯æ’­æ”¾
        }
    }

    private func startPlaybackEngine() {
        guard let playbackEngine = playbackEngine, !isPlaybackEngineRunning else { return }

        configureAudioSession()
        do {
            try playbackEngine.start()
            playerNode?.play()
            isPlaybackEngineRunning = true
            print("âœ… [TTS] æ’­æ”¾å¼•æ“å·²å¯åŠ¨")
        } catch {
            print("âŒ [TTS] æ’­æ”¾å¼•æ“å¯åŠ¨å¤±è´¥: \(error)")
        }
    }

    private func stopPlaybackEngine() {
        playerNode?.stop()
        playerNode?.reset()
        playbackEngine?.stop()
        isPlaybackEngineRunning = false
    }

    // MARK: - API Request Models

    struct TTSRequest: Codable {
        let model: String
        let input: Input

        struct Input: Codable {
            let text: String
            let voice: String
            let language_type: String
        }
    }

    // MARK: - Public Methods

    /// é¢„é…ç½®éŸ³é¢‘ä¼šè¯ï¼ˆåœ¨åœæ­¢æµä¹‹å‰è°ƒç”¨ï¼‰
    func prepareAudioSession() {
        configureAudioSession()
        print("ğŸ”Š [TTS] éŸ³é¢‘ä¼šè¯å·²é¢„é…ç½®")
    }

    /// æ’­æŠ¥æ–‡æœ¬
    /// - é˜¿é‡Œäº‘ APIï¼šä½¿ç”¨é˜¿é‡Œäº‘ qwen3-tts-flash
    /// - OpenRouter APIï¼šä½¿ç”¨ç³»ç»Ÿ TTS
    func speak(_ text: String, apiKey: String? = nil) {
        // å–æ¶ˆä¹‹å‰çš„ä»»åŠ¡
        currentTask?.cancel()
        stop()

        // OpenRouter ä½¿ç”¨ç³»ç»Ÿ TTS
        if APIProviderManager.staticCurrentProvider == .openrouter {
            print("ğŸ”Š [TTS] OpenRouter mode, using system TTS")
            isSpeaking = true
            currentTask = Task {
                await fallbackToSystemTTS(text: text)
                isSpeaking = false
            }
            return
        }

        // é˜¿é‡Œäº‘ï¼šä½¿ç”¨é˜¿é‡Œäº‘ TTS
        let key = apiKey ?? APIKeyManager.shared.getAPIKey(for: .alibaba)

        guard let finalKey = key, !finalKey.isEmpty else {
            print("âŒ [TTS] No Alibaba API key, falling back to system TTS")
            isSpeaking = true
            currentTask = Task {
                await fallbackToSystemTTS(text: text)
                isSpeaking = false
            }
            return
        }

        print("ğŸ”Š [TTS] Speaking with qwen3-tts-flash: \(text.prefix(50))...")

        isSpeaking = true

        currentTask = Task {
            do {
                try await synthesizeAndPlay(text: text, apiKey: finalKey)
            } catch {
                if !Task.isCancelled {
                    print("âŒ [TTS] Error: \(error)")
                    // å¤±è´¥æ—¶å›é€€åˆ°ç³»ç»Ÿ TTS
                    await fallbackToSystemTTS(text: text)
                }
            }
            if !Task.isCancelled {
                isSpeaking = false
            }
        }
    }

    /// åœæ­¢æ’­æŠ¥
    func stop() {
        currentTask?.cancel()
        currentTask = nil
        stopPlaybackEngine()
        isSpeaking = false
        print("ğŸ”Š [TTS] Stopped")
    }

    // MARK: - Private Methods

    private func synthesizeAndPlay(text: String, apiKey: String) async throws {
        var request = URLRequest(url: URL(string: baseURL)!)
        request.httpMethod = "POST"
        request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        request.setValue("enable", forHTTPHeaderField: "X-DashScope-SSE")
        request.timeoutInterval = 30

        let ttsRequest = TTSRequest(
            model: model,
            input: TTSRequest.Input(
                text: text,
                voice: voice,
                language_type: languageType
            )
        )

        request.httpBody = try JSONEncoder().encode(ttsRequest)

        print("ğŸ“¡ [TTS] Sending request to qwen3-tts-flash...")

        // ä½¿ç”¨ URLSession çš„ bytes API å¤„ç† SSE
        let (bytes, response) = try await URLSession.shared.bytes(for: request)

        guard let httpResponse = response as? HTTPURLResponse else {
            throw TTSError.invalidResponse
        }

        guard httpResponse.statusCode == 200 else {
            print("âŒ [TTS] API error: \(httpResponse.statusCode)")
            throw TTSError.apiError(statusCode: httpResponse.statusCode)
        }

        // å…ˆé…ç½®éŸ³é¢‘ä¼šè¯ï¼ˆå¦‚æœè¿˜æ²¡é…ç½®ï¼‰
        configureAudioSession()

        // é‡æ–°åˆå§‹åŒ–å¹¶å¯åŠ¨æ’­æ”¾å¼•æ“
        stopPlaybackEngine()
        setupPlaybackEngine()
        startPlaybackEngine()

        // æå‰è°ƒç”¨ play()ï¼Œè®© playerNode å‡†å¤‡å¥½æ¥æ”¶ buffer
        playerNode?.play()
        print("â–¶ï¸ [TTS] æ’­æ”¾å¼•æ“å’Œ playerNode å·²å°±ç»ª")

        guard isPlaybackEngineRunning else {
            print("âŒ [TTS] æ’­æ”¾å¼•æ“æœªè¿è¡Œ")
            throw TTSError.playbackFailed
        }

        var chunkCount = 0
        var totalBytes = 0

        for try await line in bytes.lines {
            if Task.isCancelled { return }

            // SSE æ ¼å¼: "data: {...}"
            if line.hasPrefix("data:") {
                let jsonString = String(line.dropFirst(5)).trimmingCharacters(in: .whitespaces)

                if jsonString == "[DONE]" {
                    break
                }

                if let jsonData = jsonString.data(using: .utf8),
                   let json = try? JSONSerialization.jsonObject(with: jsonData) as? [String: Any],
                   let output = json["output"] as? [String: Any],
                   let audio = output["audio"] as? [String: Any],
                   let audioString = audio["data"] as? String,
                   !audioString.isEmpty,
                   let audioData = Data(base64Encoded: audioString),
                   !audioData.isEmpty {
                    chunkCount += 1
                    totalBytes += audioData.count
                    if chunkCount == 1 {
                        print("ğŸ”Š [TTS] æ”¶åˆ°ç¬¬ä¸€ä¸ªéŸ³é¢‘ç‰‡æ®µ: \(audioData.count) bytes")
                    }
                    // æµå¼æ’­æ”¾æ¯ä¸ªéŸ³é¢‘ç‰‡æ®µ
                    playAudioChunk(audioData)
                }
            }
        }

        if Task.isCancelled { return }

        print("ğŸ”Š [TTS] Received \(chunkCount) chunks, \(totalBytes) bytes total")

        // ç­‰å¾…æ’­æ”¾å®Œæˆ
        await waitForPlaybackCompletion()

        print("ğŸ”Š [TTS] Finished playing")
    }

    private func playAudioChunk(_ audioData: Data) {
        // è·³è¿‡ç©ºæ•°æ®
        guard !audioData.isEmpty else {
            return
        }

        guard let playerNode = playerNode,
              let playbackFormat = playbackFormat else {
            print("âš ï¸ [TTS] playerNode æˆ– playbackFormat æœªåˆå§‹åŒ–")
            return
        }

        guard let pcmBuffer = createPCMBuffer(from: audioData, format: playbackFormat) else {
            print("âš ï¸ [TTS] æ— æ³•åˆ›å»º PCM buffer, audioData.count=\(audioData.count)")
            return
        }

        // ç¡®ä¿æ’­æ”¾å¼•æ“è¿è¡Œä¸­
        if !isPlaybackEngineRunning {
            startPlaybackEngine()
        }

        // ç¡®ä¿ playerNode åœ¨æ’­æ”¾çŠ¶æ€ï¼ˆå’Œ OmniRealtimeService ä¸€è‡´ï¼‰
        if !playerNode.isPlaying {
            playerNode.play()
            print("â–¶ï¸ [TTS] playerNode.play() å·²è°ƒç”¨")
        }

        // è°ƒåº¦éŸ³é¢‘ç¼“å†²åŒºæ’­æ”¾
        playerNode.scheduleBuffer(pcmBuffer)
    }

    private func createPCMBuffer(from data: Data, format: AVAudioFormat) -> AVAudioPCMBuffer? {
        // æœåŠ¡å™¨å‘é€çš„æ˜¯ PCM16 æ ¼å¼ï¼Œæ¯å¸§ 2 å­—èŠ‚
        let frameCount = data.count / 2
        guard frameCount > 0 else {
            print("âš ï¸ [TTS] createPCMBuffer: frameCount is 0, data.count=\(data.count)")
            return nil
        }

        guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: AVAudioFrameCount(frameCount)) else {
            print("âš ï¸ [TTS] createPCMBuffer: Failed to create AVAudioPCMBuffer, format=\(format), frameCount=\(frameCount)")
            return nil
        }

        guard let channelData = buffer.floatChannelData else {
            print("âš ï¸ [TTS] createPCMBuffer: floatChannelData is nil")
            return nil
        }

        buffer.frameLength = AVAudioFrameCount(frameCount)

        // å°† PCM16 è½¬æ¢ä¸º Float32ï¼ˆå…¼å®¹ iOS 18+ï¼‰
        data.withUnsafeBytes { (bytes: UnsafeRawBufferPointer) in
            guard let baseAddress = bytes.baseAddress else { return }
            let int16Pointer = baseAddress.assumingMemoryBound(to: Int16.self)
            let floatData = channelData[0]
            for i in 0..<frameCount {
                // Int16 èŒƒå›´ -32768 åˆ° 32767ï¼Œè½¬æ¢ä¸º -1.0 åˆ° 1.0
                floatData[i] = Float(int16Pointer[i]) / 32768.0
            }
        }

        return buffer
    }

    private func waitForPlaybackCompletion() async {
        guard let playerNode = playerNode else { return }

        // ç­‰å¾…æ‰€æœ‰éŸ³é¢‘æ’­æ”¾å®Œæˆ
        while playerNode.isPlaying {
            if Task.isCancelled { return }
            try? await Task.sleep(nanoseconds: 100_000_000) // 0.1ç§’
        }

        // é¢å¤–ç­‰å¾…ç¡®ä¿å®Œå…¨æ’­æ”¾
        try? await Task.sleep(nanoseconds: 300_000_000) // 0.3ç§’
    }

    /// å›é€€åˆ°ç³»ç»Ÿ TTS
    private func fallbackToSystemTTS(text: String) async {
        print("ğŸ”Š [TTS] Falling back to system TTS")

        // ç³»ç»Ÿ TTS ä½¿ç”¨ Playback æ¨¡å¼ï¼ˆä¸æ˜¯ PlayAndRecordï¼‰
        do {
            let audioSession = AVAudioSession.sharedInstance()
            try audioSession.setCategory(.playback, mode: .default, options: [.duckOthers])
            try audioSession.setActive(true)
            print("âœ… [TTS] System TTS audio session configured")
        } catch {
            print("âš ï¸ [TTS] System TTS audio session error: \(error)")
        }

        // ä½¿ç”¨å®ä¾‹å˜é‡ä¿æŒå¼ºå¼•ç”¨ï¼Œé˜²æ­¢è¢«é‡Šæ”¾
        systemSynthesizer = AVSpeechSynthesizer()

        guard let synthesizer = systemSynthesizer else { return }

        let utterance = AVSpeechUtterance(string: text)
        // æ ¹æ®å½“å‰è¯­è¨€è®¾ç½®é€‰æ‹©ç³»ç»Ÿè¯­éŸ³
        let voiceLanguage = LanguageManager.staticIsChinese ? "zh-CN" : "en-US"
        utterance.voice = AVSpeechSynthesisVoice(language: voiceLanguage)
        utterance.rate = AVSpeechUtteranceDefaultSpeechRate * 1.0
        utterance.volume = 1.0
        utterance.pitchMultiplier = 1.0

        print("ğŸ”Š [TTS] System TTS speaking: \(text.prefix(30))...")
        synthesizer.speak(utterance)

        // ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©æ’­æ”¾å¼€å§‹
        try? await Task.sleep(nanoseconds: 100_000_000)

        // ç­‰å¾…æ’­æ”¾å®Œæˆ
        while synthesizer.isSpeaking {
            if Task.isCancelled {
                synthesizer.stopSpeaking(at: .immediate)
                systemSynthesizer = nil
                return
            }
            try? await Task.sleep(nanoseconds: 100_000_000)
        }

        print("âœ… [TTS] System TTS finished")
        systemSynthesizer = nil
    }
}

// MARK: - Error Types

enum TTSError: LocalizedError {
    case noAPIKey
    case invalidResponse
    case apiError(statusCode: Int)
    case noAudioData
    case playbackFailed

    var errorDescription: String? {
        switch self {
        case .noAPIKey:
            return "æœªé…ç½® API Key"
        case .invalidResponse:
            return "æ— æ•ˆçš„å“åº”"
        case .apiError(let statusCode):
            return "API é”™è¯¯: \(statusCode)"
        case .noAudioData:
            return "æœªæ”¶åˆ°éŸ³é¢‘æ•°æ®"
        case .playbackFailed:
            return "éŸ³é¢‘æ’­æ”¾å¤±è´¥"
        }
    }
}
